#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦è§†é¢‘è½¬æ¢ç¨‹åº - Gradioç½‘é¡µç•Œé¢
"""

import gradio as gr
import os
import cv2
import numpy as np
from PIL import Image
import tempfile
import subprocess
import shutil
import glob
from depth_video_converter import DepthVideoConverter
from images_to_video import ImageSequenceToVideo


def process_image(input_image, model_name, device, output_format, black_threshold, 
                 depth_mode, dominant_weight, depth_range_min, depth_range_max, 
                 similarity_threshold, custom_color_map, temporal_stability, global_normalization):
    """å¤„ç†å›¾åƒ"""
    try:
        # ä¿å­˜ä¸Šä¼ çš„å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            input_image.save(tmp_file.name)
            input_path = tmp_file.name
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
        output_path = tempfile.mktemp(suffix='.jpg')
        
        # å¤„ç†é¢œè‰²æ·±åº¦é…ç½®
        color_depth_config = {}
        custom_map = {}
        
        if depth_mode == "color_based":
            color_depth_config = {
                "dominant_weight": dominant_weight,
                "depth_range": [depth_range_min, depth_range_max],
                "similarity_threshold": similarity_threshold
            }
        elif depth_mode == "custom" and custom_color_map:
            # è§£æè‡ªå®šä¹‰é¢œè‰²æ˜ å°„
            try:
                import json
                custom_map = json.loads(custom_color_map)
            except:
                custom_map = {}
        
        # åˆå§‹åŒ–è½¬æ¢å™¨
        converter = DepthVideoConverter(
            model_name=model_name,
            device=device,
            output_format=output_format,
            black_threshold=black_threshold,
            depth_mode=depth_mode,
            color_depth_config=color_depth_config,
            custom_color_map=custom_map,
            temporal_stability=temporal_stability,
            global_normalization=global_normalization
        )
        
        # å¤„ç†å›¾åƒ
        success = converter.process_image(input_path, output_path)
        
        if success and os.path.exists(output_path):
            # è¯»å–å¤„ç†åçš„å›¾åƒ
            result_image = cv2.imread(output_path)
            result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(input_path)
            
            return result_image, output_path
        else:
            os.unlink(input_path)
            return None, None
            
    except Exception as e:
        print(f"å›¾åƒå¤„ç†é”™è¯¯: {e}")
        return None, None


def process_video(input_video, model_name, device, output_format, black_threshold, 
                 start_frame, max_frames, fps, force_images, auto_convert, 
                 video_codec, video_quality, depth_mode, dominant_weight, 
                 depth_range_min, depth_range_max, similarity_threshold, custom_color_map,
                 temporal_stability, global_normalization):
    """å¤„ç†è§†é¢‘"""
    try:
        # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as tmp_file:
            # è¯»å–è§†é¢‘æ–‡ä»¶å†…å®¹
            with open(input_video, 'rb') as f:
                tmp_file.write(f.read())
            input_path = tmp_file.name
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
        output_path = tempfile.mktemp(suffix='.mp4')
        
        # å¤„ç†é¢œè‰²æ·±åº¦é…ç½®
        color_depth_config = {}
        custom_map = {}
        
        if depth_mode == "color_based":
            color_depth_config = {
                "dominant_weight": dominant_weight,
                "depth_range": [depth_range_min, depth_range_max],
                "similarity_threshold": similarity_threshold
            }
        elif depth_mode == "custom" and custom_color_map:
            # è§£æè‡ªå®šä¹‰é¢œè‰²æ˜ å°„
            try:
                import json
                custom_map = json.loads(custom_color_map)
            except:
                custom_map = {}
        
        # åˆå§‹åŒ–è½¬æ¢å™¨
        converter = DepthVideoConverter(
            model_name=model_name,
            device=device,
            output_format=output_format,
            black_threshold=black_threshold,
            depth_mode=depth_mode,
            color_depth_config=color_depth_config,
            custom_color_map=custom_map,
            temporal_stability=temporal_stability,
            global_normalization=global_normalization
        )
        
        # å¤„ç†è§†é¢‘
        if force_images:
            # å¼ºåˆ¶å›¾åƒåºåˆ—è¾“å‡º
            cap = cv2.VideoCapture(input_path)
            if not cap.isOpened():
                os.unlink(input_path)
                return None
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if max_frames is None or max_frames == 0:
                max_frames = total_frames - start_frame
            else:
                max_frames = min(max_frames, total_frames - start_frame)
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            success = converter._process_video_as_images(
                cap, output_path, max_frames, start_frame, fps or 30.0, auto_convert
            )
        else:
            success = converter.process_video(
                input_path=input_path,
                output_path=output_path,
                start_frame=start_frame,
                max_frames=max_frames,
                fps=fps
            )
        
        # å¦‚æœè‡ªåŠ¨è½¬æ¢å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è½¬æ¢
        if auto_convert and force_images and success:
            images_dir = output_path.replace('.mp4', '_frames').replace('.avi', '_frames')
            if os.path.exists(images_dir):
                # ä½¿ç”¨ç‹¬ç«‹çš„å›¾åƒåºåˆ—è½¬è§†é¢‘å·¥å…·
                video_converter = ImageSequenceToVideo()
                final_video_path = output_path.replace('_frames', '')
                convert_success = video_converter.convert_images_to_video(
                    images_dir, final_video_path, fps or 30.0, video_codec, video_quality
                )
                if convert_success:
                    output_path = final_video_path
                    # æ¸…ç†å›¾åƒåºåˆ—ç›®å½•
                    shutil.rmtree(images_dir)
        
        if success and os.path.exists(output_path):
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(input_path)
            return output_path
        else:
            os.unlink(input_path)
            return None
            
    except Exception as e:
        print(f"è§†é¢‘å¤„ç†é”™è¯¯: {e}")
        return None


def convert_images_to_video(images_dir, output_path, fps, codec, quality):
    """å°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘"""
    try:
        if not os.path.exists(images_dir):
            return None, "å›¾åƒç›®å½•ä¸å­˜åœ¨"
        
        # æ£€æŸ¥å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(glob.glob(os.path.join(images_dir, ext)))
        
        if not image_files:
            return None, "æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶"
        
        # ä½¿ç”¨å›¾åƒåºåˆ—è½¬è§†é¢‘å·¥å…·
        converter = ImageSequenceToVideo()
        success = converter.convert_images_to_video(
            images_dir, output_path, fps, codec, quality
        )
        
        if success and os.path.exists(output_path):
            return output_path, f"âœ… è½¬æ¢æˆåŠŸï¼Œå…±å¤„ç† {len(image_files)} å¸§"
        else:
            return None, "âŒ è½¬æ¢å¤±è´¥"
            
    except Exception as e:
        return None, f"âŒ è½¬æ¢é”™è¯¯: {e}"


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    css = """
    .gradio-container {
        max-width: 100% !important;
        width: 100% !important;
    }
    .main-header {
        text-align: center;
        margin-bottom: 20px;
    }
    .section-title {
        font-size: 16px;
        font-weight: bold;
        margin: 15px 0 8px 0;
        color: #2c3e50;
        padding: 8px 12px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 6px;
        text-align: center;
    }
    .param-group {
        background: #f8f9fa;
        padding: 12px;
        border-radius: 8px;
        margin-bottom: 10px;
        border-left: 4px solid #667eea;
    }
    .compact-row {
        display: flex;
        gap: 10px;
        margin-bottom: 8px;
    }
    .compact-row > * {
        flex: 1;
    }
    
    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 1200px) {
        .gradio-container {
            padding: 10px !important;
        }
        .section-title {
            font-size: 14px !important;
            padding: 6px 10px !important;
        }
    }
    
    @media (max-width: 768px) {
        .gradio-container {
            padding: 5px !important;
        }
        .section-title {
            font-size: 12px !important;
            padding: 4px 8px !important;
        }
    }
    
    /* ç¡®ä¿åœ¨å°å±å¹•ä¸Šåˆ—å¸ƒå±€è‡ªé€‚åº” */
    @media (max-width: 1024px) {
        .gradio-row {
            flex-direction: column !important;
        }
        .gradio-column {
            width: 100% !important;
            margin-bottom: 20px !important;
        }
    }
    """
    
    with gr.Blocks(css=css, title="æ·±åº¦è§†é¢‘è½¬æ¢å™¨") as demo:
        
        # æ ‡é¢˜
        gr.HTML("""
        <div class="main-header">
            <h1>ğŸ¥ æ·±åº¦è§†é¢‘è½¬æ¢å™¨</h1>
            <p>å°†æ™®é€šè§†é¢‘/å›¾åƒè½¬æ¢ä¸ºåŒ…å«æ·±åº¦ä¿¡æ¯çš„è§†é¢‘/å›¾åƒï¼Œæ”¯æŒé»‘è‰²èƒŒæ™¯ä¿æŒ</p>
        </div>
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šå‚æ•°è®¾ç½® (30%)
            with gr.Column(scale=1.2):
                gr.HTML('<div class="section-title">âš™ï¸ åŸºç¡€è®¾ç½®</div>')
                
                with gr.Group():
                    depth_mode = gr.Dropdown(
                        choices=["ai", "color_based", "custom"],
                        value="ai",
                        label="æ·±åº¦è®¡ç®—æ¨¡å¼",
                        info="ai: AIæ¨¡å‹ | color_based: é¢œè‰²åˆ†æ | custom: è‡ªå®šä¹‰æ˜ å°„"
                    )
                    
                    model_name = gr.Dropdown(
                        choices=[
                            "Intel/dpt-large",
                            "Intel/dpt-hybrid-midas", 
                            "facebook/dpt-dinov2-small-kitti"
                        ],
                        value="Intel/dpt-large",
                        label="æ·±åº¦ä¼°è®¡æ¨¡å‹",
                        info="Intel/dpt-large: é«˜ç²¾åº¦ | Intel/dpt-hybrid-midas: å¹³è¡¡ | facebook/dpt-dinov2-small-kitti: å¿«é€Ÿ",
                        visible=True
                    )
                    
                    with gr.Row():
                        device = gr.Dropdown(
                            choices=["auto", "cuda", "cpu"],
                            value="auto",
                            label="è®¡ç®—è®¾å¤‡",
                            info="auto: è‡ªåŠ¨é€‰æ‹© | cuda: GPUåŠ é€Ÿ | cpu: CPUå¤„ç†"
                        )
                        output_format = gr.Dropdown(
                            choices=["side_by_side", "depth_only", "overlay"],
                            value="depth_only",
                            label="è¾“å‡ºæ ¼å¼",
                            info="side_by_side: å¹¶æ’æ˜¾ç¤º | depth_only: çº¯æ·±åº¦å›¾ | overlay: å åŠ æ˜¾ç¤º"
                        )
                    
                    black_threshold = gr.Slider(
                        minimum=10,
                        maximum=100,
                        value=30,
                        step=5,
                        label="é»‘è‰²èƒŒæ™¯é˜ˆå€¼",
                        info="RGBå€¼ä½äºæ­¤é˜ˆå€¼çš„åƒç´ å°†è¢«è¯†åˆ«ä¸ºé»‘è‰²èƒŒæ™¯"
                    )
                
                gr.HTML('<div class="section-title">ğŸ¨ é¢œè‰²æ·±åº¦è®¾ç½®</div>')
                
                with gr.Group():
                    dominant_weight = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.7,
                        step=0.1,
                        label="ä¸»è‰²è°ƒæƒé‡",
                        info="ä¸»è‰²è°ƒåŒºåŸŸçš„æ·±åº¦æƒé‡ (0.1-1.0)",
                        visible=True
                    )
                    
                    with gr.Row():
                        depth_range_min = gr.Slider(
                            minimum=0,
                            maximum=150,
                            value=50,
                            step=10,
                            label="æœ€å°æ·±åº¦",
                            info="æœ€å°æ·±åº¦å€¼",
                            visible=True
                        )
                        depth_range_max = gr.Slider(
                            minimum=100,
                            maximum=255,
                            value=200,
                            step=10,
                            label="æœ€å¤§æ·±åº¦",
                            info="æœ€å¤§æ·±åº¦å€¼",
                            visible=True
                        )
                    
                    similarity_threshold = gr.Slider(
                        minimum=10,
                        maximum=100,
                        value=30,
                        step=5,
                        label="é¢œè‰²ç›¸ä¼¼åº¦é˜ˆå€¼",
                        info="é¢œè‰²ç›¸ä¼¼åº¦åˆ¤æ–­é˜ˆå€¼",
                        visible=True
                    )
                    
                    custom_color_map = gr.Textbox(
                        label="è‡ªå®šä¹‰é¢œè‰²æ˜ å°„ (JSONæ ¼å¼)",
                        placeholder='{"çº¢è‰²": 200, "ç»¿è‰²": 150, "è“è‰²": 100}',
                        info="è‡ªå®šä¹‰é¢œè‰²æ·±åº¦æ˜ å°„ï¼ŒJSONæ ¼å¼",
                        lines=3,
                        visible=False
                    )
                
                gr.HTML('<div class="section-title">ğŸ¬ è§†é¢‘å¤„ç†å‚æ•°</div>')
                
                with gr.Group():
                    with gr.Row():
                        start_frame = gr.Number(value=0, label="èµ·å§‹å¸§", info="ä»ç¬¬å‡ å¸§å¼€å§‹å¤„ç†")
                        max_frames = gr.Number(value=None, label="æœ€å¤§å¤„ç†å¸§æ•°", info="æœ€å¤šå¤„ç†å¤šå°‘å¸§ï¼ˆç•™ç©ºå¤„ç†å…¨éƒ¨ï¼‰")
                    
                    fps = gr.Number(value=None, label="è¾“å‡ºå¸§ç‡", info="è¾“å‡ºè§†é¢‘çš„å¸§ç‡ï¼ˆç•™ç©ºä¿æŒåŸå¸§ç‡ï¼‰")
                
                gr.HTML('<div class="section-title">ğŸ¬ FFmpegè®¾ç½®</div>')
                
                with gr.Group():
                    with gr.Row():
                        force_images = gr.Checkbox(value=False, label="å¼ºåˆ¶å›¾åƒåºåˆ—è¾“å‡º", info="è·³è¿‡è§†é¢‘ç¼–ç å™¨ï¼Œç›´æ¥è¾“å‡ºå›¾åƒåºåˆ—")
                        auto_convert = gr.Checkbox(value=True, label="è‡ªåŠ¨è½¬æ¢ä¸ºè§†é¢‘", info="ä½¿ç”¨FFmpegå°†å›¾åƒåºåˆ—è‡ªåŠ¨è½¬æ¢ä¸ºè§†é¢‘")
                    
                    with gr.Row():
                        video_codec = gr.Dropdown(
                            choices=["libx264", "libx265", "libvpx-vp9"],
                            value="libx264",
                            label="è§†é¢‘ç¼–ç å™¨",
                            info="libx264: å…¼å®¹æ€§å¥½ | libx265: å‹ç¼©ç‡é«˜ | libvpx-vp9: Webä¼˜åŒ–"
                        )
                        video_quality = gr.Dropdown(
                            choices=["low", "medium", "high", "lossless"],
                            value="medium",
                            label="è§†é¢‘è´¨é‡",
                            info="low: å¿«é€Ÿ | medium: å¹³è¡¡ | high: é«˜è´¨é‡ | lossless: æ— æŸ"
                        )
                
                gr.HTML('<div class="section-title">ğŸ”§ æ—¶åºç¨³å®šæ€§è®¾ç½®</div>')
                
                with gr.Group():
                    temporal_stability = gr.Checkbox(
                        value=True, 
                        label="å¯ç”¨æ—¶åºç¨³å®šæ€§", 
                        info="å‡å°‘ç›¸é‚»å¸§ä¹‹é—´çš„æ·±åº¦å€¼çªå˜ï¼Œæé«˜è§†é¢‘ç¨³å®šæ€§"
                    )
                    
                    global_normalization = gr.Checkbox(
                        value=True, 
                        label="ä½¿ç”¨å…¨å±€æ·±åº¦å½’ä¸€åŒ–", 
                        info="ä½¿ç”¨æ•´ä¸ªè§†é¢‘çš„æ·±åº¦èŒƒå›´è¿›è¡Œå½’ä¸€åŒ–ï¼Œç¡®ä¿é¢œè‰²ä¸€è‡´æ€§"
                    )
            
            # ä¸­é—´ï¼šå›¾åƒå’Œè§†é¢‘å¤„ç† (40%)
            with gr.Column(scale=1.6):
                gr.HTML('<div class="section-title">ğŸ–¼ï¸ å›¾åƒå¤„ç†</div>')
                
                with gr.Row():
                    image_input = gr.Image(
                        label="ä¸Šä¼ å›¾åƒ",
                        type="pil",
                        height=300
                    )
                    
                    image_output = gr.Image(
                        label="å¤„ç†ç»“æœ",
                        height=300
                    )
                
                image_process_btn = gr.Button("ğŸš€ å¤„ç†å›¾åƒ", variant="primary", size="lg")
                image_download = gr.File(label="ä¸‹è½½ç»“æœ")
                
                gr.HTML('<div class="section-title">ğŸ¥ è§†é¢‘å¤„ç†</div>')
                
                video_input = gr.Video(
                    label="ä¸Šä¼ è§†é¢‘",
                    height=250
                )
                
                video_process_btn = gr.Button("ğŸš€ å¤„ç†è§†é¢‘", variant="primary", size="lg")
                
                with gr.Row():
                    video_output = gr.Video(
                        label="å¤„ç†ç»“æœé¢„è§ˆ",
                        height=300,
                        show_download_button=True
                    )
                    video_download = gr.File(label="ä¸‹è½½ç»“æœ")
            
            # å³ä¾§ï¼šå›¾åƒåºåˆ—è½¬æ¢å’ŒçŠ¶æ€ (30%)
            with gr.Column(scale=1.2):
                gr.HTML('<div class="section-title">ğŸ”„ å›¾åƒåºåˆ—è½¬è§†é¢‘</div>')
                
                with gr.Group():
                    images_dir_input = gr.Textbox(
                        label="å›¾åƒåºåˆ—ç›®å½•è·¯å¾„",
                        placeholder="è¾“å…¥åŒ…å«å›¾åƒæ–‡ä»¶çš„ç›®å½•è·¯å¾„",
                        info="ç›®å½•åº”åŒ…å«æŒ‰é¡ºåºå‘½åçš„å›¾åƒæ–‡ä»¶ï¼ˆå¦‚frame_000001.jpgï¼‰",
                        lines=2
                    )
                    
                    convert_btn = gr.Button("ğŸ”„ è½¬æ¢å›¾åƒåºåˆ—", variant="secondary", size="lg")
                    
                    with gr.Row():
                        convert_output = gr.Video(
                            label="è½¬æ¢ç»“æœé¢„è§ˆ",
                            height=300,
                            show_download_button=True
                        )
                        convert_download = gr.File(label="ä¸‹è½½è½¬æ¢ç»“æœ")
                
                gr.HTML('<div class="section-title">ğŸ“Š å¤„ç†çŠ¶æ€</div>')
                
                with gr.Group():
                    status_text = gr.Textbox(
                        label="å¤„ç†çŠ¶æ€",
                        value="ç­‰å¾…å¤„ç†...",
                        interactive=False,
                        lines=4
                    )
                    
                    # æ·»åŠ ä¸€äº›ç»Ÿè®¡ä¿¡æ¯
                    gr.HTML("""
                    <div style="margin-top: 10px; padding: 10px; background: #e8f4fd; border-radius: 6px;">
                        <h4 style="margin: 0 0 8px 0; color: #2c3e50;">ğŸ’¡ ä½¿ç”¨æç¤º</h4>
                    <ul style="margin: 0; padding-left: 20px; font-size: 13px;">
                        <li>GPUåŠ é€Ÿå¤„ç†é€Ÿåº¦æ›´å¿«</li>
                        <li>depth_onlyæ ¼å¼å¤„ç†æœ€å¿«</li>
                        <li>å¼ºåˆ¶å›¾åƒåºåˆ—å¯é¿å…ç¼–ç é—®é¢˜</li>
                        <li>æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶</li>
                        <li>æ—¶åºç¨³å®šæ€§å‡å°‘é¢œè‰²çªå˜</li>
                    </ul>
                    </div>
                    """)
        
        # æ§åˆ¶ç•Œé¢å…ƒç´ æ˜¾ç¤º/éšè—
        def update_ui_visibility(depth_mode):
            if depth_mode == "ai":
                return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)
            elif depth_mode == "color_based":
                return gr.update(visible=False), gr.update(visible=True), gr.update(visible=True), gr.update(visible=True), gr.update(visible=True), gr.update(visible=False)
            else:  # custom
                return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)
        
        # äº‹ä»¶å¤„ç†
        def process_image_wrapper(input_image, model_name, device, output_format, black_threshold,
                                depth_mode, dominant_weight, depth_range_min, depth_range_max,
                                similarity_threshold, custom_color_map, temporal_stability, global_normalization):
            if input_image is None:
                return None, None, "è¯·å…ˆä¸Šä¼ å›¾åƒ"
            
            status_text = "æ­£åœ¨å¤„ç†å›¾åƒ..."
            result_image, output_path = process_image(
                input_image, model_name, device, output_format, black_threshold,
                depth_mode, dominant_weight, depth_range_min, depth_range_max,
                similarity_threshold, custom_color_map, temporal_stability, global_normalization
            )
            
            if result_image is not None:
                status_text = "âœ… å›¾åƒå¤„ç†å®Œæˆ"
                return result_image, output_path, status_text
            else:
                status_text = "âŒ å›¾åƒå¤„ç†å¤±è´¥"
                return None, None, status_text
        
        def process_video_wrapper(input_video, model_name, device, output_format, 
                                black_threshold, start_frame, max_frames, fps,
                                force_images, auto_convert, video_codec, video_quality,
                                depth_mode, dominant_weight, depth_range_min, depth_range_max,
                                similarity_threshold, custom_color_map, temporal_stability, global_normalization):
            if input_video is None:
                return None, None, "è¯·å…ˆä¸Šä¼ è§†é¢‘"
            
            status_text = "æ­£åœ¨å¤„ç†è§†é¢‘..."
            output_path = process_video(
                input_video, model_name, device, output_format, 
                black_threshold, start_frame, max_frames, fps,
                force_images, auto_convert, video_codec, video_quality,
                depth_mode, dominant_weight, depth_range_min, depth_range_max,
                similarity_threshold, custom_color_map, temporal_stability, global_normalization
            )
            
            if output_path is not None:
                status_text = "âœ… è§†é¢‘å¤„ç†å®Œæˆ"
                return output_path, output_path, status_text
            else:
                status_text = "âŒ è§†é¢‘å¤„ç†å¤±è´¥"
                return None, None, status_text
        
        def convert_images_wrapper(images_dir, fps, video_codec, video_quality):
            if not images_dir or not images_dir.strip():
                return None, None, "è¯·è¾“å…¥å›¾åƒåºåˆ—ç›®å½•è·¯å¾„"
            
            status_text = "æ­£åœ¨è½¬æ¢å›¾åƒåºåˆ—..."
            output_path = tempfile.mktemp(suffix='.mp4')
            
            result_path, result_status = convert_images_to_video(
                images_dir.strip(), output_path, fps or 30.0, video_codec, video_quality
            )
            
            if result_path is not None:
                return result_path, result_path, result_status
            else:
                return None, None, result_status
        
        # ç»‘å®šäº‹ä»¶
        # æ·±åº¦æ¨¡å¼å˜åŒ–æ—¶æ›´æ–°ç•Œé¢
        depth_mode.change(
            fn=update_ui_visibility,
            inputs=[depth_mode],
            outputs=[model_name, dominant_weight, depth_range_min, depth_range_max, similarity_threshold, custom_color_map]
        )
        
        image_process_btn.click(
            fn=process_image_wrapper,
            inputs=[image_input, model_name, device, output_format, black_threshold,
                   depth_mode, dominant_weight, depth_range_min, depth_range_max,
                   similarity_threshold, custom_color_map, temporal_stability, global_normalization],
            outputs=[image_output, image_download, status_text]
        )
        
        video_process_btn.click(
            fn=process_video_wrapper,
            inputs=[video_input, model_name, device, output_format, black_threshold, 
                   start_frame, max_frames, fps, force_images, auto_convert, 
                   video_codec, video_quality, depth_mode, dominant_weight, 
                   depth_range_min, depth_range_max, similarity_threshold, custom_color_map,
                   temporal_stability, global_normalization],
            outputs=[video_output, video_download, status_text]
        )
        
        convert_btn.click(
            fn=convert_images_wrapper,
            inputs=[images_dir_input, fps, video_codec, video_quality],
            outputs=[convert_output, convert_download, status_text]
        )
        
        # ä½¿ç”¨è¯´æ˜
        gr.HTML("""
        <div style="margin-top: 20px; padding: 15px; background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); border-radius: 10px;">
            <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;">
                <div>
                    <h3 style="margin: 0 0 10px 0; color: #2c3e50;">ğŸ“– å¿«é€ŸæŒ‡å—</h3>
                    <ul style="margin: 0; padding-left: 20px; font-size: 14px;">
                        <li><strong>AIæ¨¡å¼</strong>ï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹</li>
                        <li><strong>é¢œè‰²æ¨¡å¼</strong>ï¼šåŸºäºé¢œè‰²åˆ†æ</li>
                        <li><strong>è‡ªå®šä¹‰æ¨¡å¼</strong>ï¼šæ‰‹åŠ¨è®¾ç½®é¢œè‰²æ·±åº¦</li>
                        <li><strong>è®¾å¤‡</strong>ï¼šæœ‰GPUå»ºè®®é€‰æ‹©cuda</li>
                    </ul>
                </div>
                <div>
                    <h3 style="margin: 0 0 10px 0; color: #2c3e50;">ğŸ¨ é¢œè‰²æ·±åº¦</h3>
                    <ul style="margin: 0; padding-left: 20px; font-size: 14px;">
                        <li>âœ… ä¿æŒé»‘è‰²åŒºåŸŸä¸å˜</li>
                        <li>âœ… ä¸»è‰²è°ƒåŒºåŸŸæ·±åº¦æ›´é«˜</li>
                        <li>âœ… æ”¯æŒè‡ªå®šä¹‰é¢œè‰²æ˜ å°„</li>
                        <li>âœ… å®æ—¶è°ƒæ•´å‚æ•°</li>
                    </ul>
                </div>
                <div>
                    <h3 style="margin: 0 0 10px 0; color: #2c3e50;">ğŸ¯ ç‰¹è‰²åŠŸèƒ½</h3>
                    <ul style="margin: 0; padding-left: 20px; font-size: 14px;">
                        <li>âœ… GPUåŠ é€Ÿå¤„ç†</li>
                        <li>âœ… åœ¨çº¿è§†é¢‘é¢„è§ˆ</li>
                        <li>âœ… å¤šç§ç¼–ç å™¨æ”¯æŒ</li>
                        <li>âœ… æ‰¹é‡å¤„ç†æ”¯æŒ</li>
                        <li>âœ… æ—¶åºç¨³å®šæ€§ä¼˜åŒ–</li>
                    </ul>
                </div>
            </div>
        </div>
        """)
    
    return demo


if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨Gradioç•Œé¢
    demo = create_gradio_interface()
    
    print("ğŸš€ å¯åŠ¨æ·±åº¦è§†é¢‘è½¬æ¢å™¨ç½‘é¡µç•Œé¢...")
    print("ğŸ“± ç•Œé¢å°†åœ¨æµè§ˆå™¨ä¸­è‡ªåŠ¨æ‰“å¼€")
    print("ğŸŒ å¦‚æœæ²¡æœ‰è‡ªåŠ¨æ‰“å¼€ï¼Œè¯·è®¿é—®æ˜¾ç¤ºçš„URL")
    
    # å¯åŠ¨ç•Œé¢
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        share=False,            # æ˜¯å¦åˆ›å»ºå…¬å…±é“¾æ¥
        debug=False,            # è°ƒè¯•æ¨¡å¼
        inbrowser=True,
        show_error=True         # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    )
